# ğŸŒŸ LA AURORA - Sistema de Reuniones Ejecutivas

**Sistema inteligente de grabaciÃ³n, transcripciÃ³n y anÃ¡lisis de reuniones empresariales con IA local.**

![LA AURORA](./public/assets/logo.png)

## âœ¨ CaracterÃ­sticas Principales

- ğŸ¤ **GrabaciÃ³n en vivo** con visualizaciÃ³n de ondas de audio
- ğŸ“ **ImportaciÃ³n de archivos** MP3, WAV, M4A, WEBM
- ğŸ¤– **TranscripciÃ³n local** con Whisper (OpenAI)
- ğŸ§  **AnÃ¡lisis inteligente** con Ollama (modelos locales)
- ğŸ’¾ **GestiÃ³n de sesiones** con auto-guardado
- ğŸ—‘ï¸ **Control completo** - crear, cargar y eliminar sesiones
- ğŸ¨ **UI moderna** inspirada en Material Design
- ğŸ”’ **100% local** - sin envÃ­o de datos a terceros

## ğŸš€ InstalaciÃ³n RÃ¡pida

### Prerrequisitos
- Node.js (v16+)
- Python 3.8+
- Ollama instalado y corriendo

### 1. Clonar el repositorio
```bash
git clone https://github.com/TU_USUARIO/la-aurora.git
cd la-aurora
```

### 2. Instalar dependencias
```bash
npm run setup
```

### 3. Instalar Whisper
```bash
pip3 install openai-whisper
```

### 4. Configurar Ollama
```bash
# Instalar modelo recomendado
ollama pull gemma2:2b

# O un modelo mÃ¡s potente
ollama pull llama3.1:8b
```

### 5. Iniciar la aplicaciÃ³n
```bash
npm start
# O usar el script personalizado
./start.sh
# O crear alias
alias aurora="cd $(pwd) && node server.js"
```

## ğŸ¯ Uso

1. **Accede** a http://localhost:3000/pro
2. **Crea una nueva sesiÃ³n** con tÃ­tulo y participantes
3. **Graba en vivo** o **sube un archivo de audio**
4. **Transcribe** automÃ¡ticamente con Whisper
5. **Analiza** con diferentes plantillas de IA:
   - ğŸ“‹ Resumen Ejecutivo
   - âœ… Plan de AcciÃ³n
   - ğŸ¯ Decisiones Tomadas
   - ğŸ’¡ Ideas y Oportunidades
   - âš ï¸ Riesgos y DesafÃ­os
   - ğŸ“… Plan de Seguimiento

## ğŸ—ï¸ Arquitectura

### Frontend
- **Vanilla JavaScript** modular
- **CSS Grid/Flexbox** responsive
- **Web Audio API** para grabaciÃ³n
- **Material Design** principles

### Backend
- **Node.js + Express** server
- **Multer** para uploads
- **fs-extra** para gestiÃ³n de archivos
- **Local Whisper** via Python subprocess
- **Ollama API** para procesamiento de IA

### Estructura del Proyecto
```
la-aurora/
â”œâ”€â”€ public/
â”‚   â”œâ”€â”€ components/          # Componentes JS modulares
â”‚   â”œâ”€â”€ assets/             # Logo y recursos
â”‚   â”œâ”€â”€ styles.css          # Estilos principales
â”‚   â”œâ”€â”€ index-pro.html      # Interfaz principal
â”‚   â””â”€â”€ resumen.html        # PÃ¡gina de anÃ¡lisis
â”œâ”€â”€ sessions/               # Datos de sesiones (local)
â”œâ”€â”€ uploads/               # Archivos de audio temporales
â”œâ”€â”€ server.js              # Servidor principal
â”œâ”€â”€ whisper_transcriber.py # Script de transcripciÃ³n
â””â”€â”€ start.sh              # Script de inicio
```

## ğŸ”§ ConfiguraciÃ³n

### Variables de Entorno (Opcional)
```bash
# .env
WHISPER_MODEL=base          # tiny, base, small, medium, large
OLLAMA_MODEL=gemma2:2b     # Modelo de Ollama a usar
PORT=3000                  # Puerto del servidor
```

### Modelos Whisper Disponibles
- `tiny` - MÃ¡s rÃ¡pido, menos preciso
- `base` - Balance recomendado
- `small` - Mejor precisiÃ³n
- `medium` - Alta precisiÃ³n
- `large` - MÃ¡xima precisiÃ³n (requiere mÃ¡s RAM)

## ğŸ“Š Plantillas de AnÃ¡lisis

### Resumen Ejecutivo
Puntos clave para directivos y toma de decisiones estratÃ©gicas.

### Plan de AcciÃ³n
Tareas especÃ­ficas con responsables y fechas lÃ­mite.

### Decisiones Tomadas
Acuerdos alcanzados y compromisos establecidos.

### Ideas y Oportunidades
Insights valiosos e oportunidades identificadas.

### Riesgos y DesafÃ­os
Problemas identificados y estrategias de mitigaciÃ³n.

### Plan de Seguimiento
PrÃ³ximas reuniones y temas pendientes.

## ğŸ› ï¸ Desarrollo

### Estructura de Componentes
```javascript
// Managers principales
- SessionManager     // GestiÃ³n de sesiones
- RecordingManager   // GrabaciÃ³n de audio
- UploadManager      // Subida de archivos
- TranscriptionManager // Whisper integration
- UIManager          // Control de interfaz
- NotificationSystem // Sistema de notificaciones
```

### API Endpoints
```
GET    /api/sessions          # Listar sesiones
POST   /api/sessions          # Crear/actualizar sesiÃ³n
GET    /api/sessions/:id      # Obtener sesiÃ³n especÃ­fica
DELETE /api/sessions/:id      # Eliminar sesiÃ³n
POST   /api/sessions/analysis # Guardar anÃ¡lisis
POST   /transcribe           # Transcribir audio
POST   /process-with-ollama  # Procesar con IA
```

## ğŸš€ Despliegue

### Docker (PrÃ³ximamente)
```bash
docker build -t la-aurora .
docker run -p 3000:3000 la-aurora
```

### Servidor Local
```bash
# ProducciÃ³n
NODE_ENV=production npm start

# Con PM2
pm2 start server.js --name "la-aurora"
```

## ğŸ¤ Contribuir

1. Fork el proyecto
2. Crea una rama para tu feature (`git checkout -b feature/AmazingFeature`)
3. Commit tus cambios (`git commit -m 'Add some AmazingFeature'`)
4. Push a la rama (`git push origin feature/AmazingFeature`)
5. Abre un Pull Request

## ğŸ“ Roadmap

- [ ] ğŸ³ Docker containerization
- [ ] ğŸ” AutenticaciÃ³n de usuarios
- [ ] ğŸ“Š Dashboard de mÃ©tricas
- [ ] ğŸŒ Soporte multi-idioma
- [ ] ğŸ“± App mÃ³vil (React Native)
- [ ] â˜ï¸ IntegraciÃ³n con cloud storage
- [ ] ğŸ”— API webhooks
- [ ] ğŸ“ˆ Analytics avanzados

## ğŸ“„ Licencia

Este proyecto estÃ¡ bajo la Licencia MIT - ver el archivo [LICENSE](LICENSE) para detalles.

## ğŸ™ Agradecimientos

- [OpenAI Whisper](https://github.com/openai/whisper) - TranscripciÃ³n de audio
- [Ollama](https://ollama.ai/) - Modelos de IA locales
- [Express.js](https://expressjs.com/) - Framework web
- Comunidad open source

---

**Desarrollado con â¤ï¸ para mejorar la productividad empresarial**